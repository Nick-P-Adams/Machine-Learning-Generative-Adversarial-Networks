{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6f5jBUzsbwk1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gdown\n",
    "import PIL\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WS1idCTwvroX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset places365_small/2.0.0 (download: 29.27 GiB, generated: Unknown size, total: 29.27 GiB) to /home/nadams11/tensorflow_datasets/places365_small/2.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccc6b49cfbf48a8a4586f15fb3d108a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8eac16f4c64f2c8a34396c0db74abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DownloadError",
     "evalue": "Failed to get url http://data.csail.mit.edu/places/places365/train_256_places365standard.tar. HTTP code: 504.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Approximately 20 mins\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tfds\u001b[38;5;241m.\u001b[39mlist_builders()\n\u001b[0;32m----> 3\u001b[0m data,info\u001b[38;5;241m=\u001b[39m\u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplaces365_small\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_dataset\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/api_utils.py:69\u001b[0m, in \u001b[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m _check_no_positional(fn, args, ismethod, allowed\u001b[38;5;241m=\u001b[39mallowed)\n\u001b[1;32m     68\u001b[0m _check_required(fn, kwargs)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/registered.py:369\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m    368\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 369\u001b[0m   \u001b[43mdbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/api_utils.py:69\u001b[0m, in \u001b[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m _check_no_positional(fn, args, ismethod, allowed\u001b[38;5;241m=\u001b[39mallowed)\n\u001b[1;32m     68\u001b[0m _check_required(fn, kwargs)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py:361\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mread_from_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_dir)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 361\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[1;32m    366\u001b[0m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[1;32m    367\u001b[0m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[1;32m    368\u001b[0m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m   splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py:994\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, download_config):\n\u001b[1;32m    993\u001b[0m   \u001b[38;5;66;03m# Extract max_examples_per_split and forward it to _prepare_split\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGeneratorBasedBuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_examples_per_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_examples_per_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py:915\u001b[0m, in \u001b[0;36mFileAdapterBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m splits_lib\u001b[38;5;241m.\u001b[39mSplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    913\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(\n\u001b[1;32m    914\u001b[0m     prepare_split_kwargs)\n\u001b[0;32m--> 915\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_generator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    917\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(split_generator\u001b[38;5;241m.\u001b[39msplit_info\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`all` is a special split keyword corresponding to the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munion of all splits, so cannot be used as key in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    921\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m._split_generator().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/image_classification/places365_small.py:76\u001b[0m, in \u001b[0;36mPlaces365Small._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_generators\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager):\n\u001b[0;32m---> 76\u001b[0m   output_archives \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murljoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_BASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_TRAIN_URL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murljoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_BASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_TEST_URL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murljoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_BASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_VALID_URL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m   annotation_path \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownload_and_extract(\n\u001b[1;32m     82\u001b[0m       urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murljoin(_BASE_URL, _FILE_ANNOTATION_URL))\n\u001b[1;32m     84\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     85\u001b[0m       tfds\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mSplitGenerator(\n\u001b[1;32m     86\u001b[0m           name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m       ),\n\u001b[1;32m    125\u001b[0m   ]\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/download/download_manager.py:361\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# Add progress bar to follow the download state\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_downloader\u001b[38;5;241m.\u001b[39mtqdm():\n\u001b[0;32m--> 361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_promise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/download/download_manager.py:462\u001b[0m, in \u001b[0;36m_map_promise\u001b[0;34m(map_fn, all_inputs)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[1;32m    461\u001b[0m all_promises \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmap_nested(map_fn, all_inputs)  \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_wait_on_promise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_promises\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/utils/py_utils.py:151\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Could add support for more exotic data_struct, like OrderedDict\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 151\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    152\u001b[0m       k: map_nested(function, v, dict_only, map_tuple)\n\u001b[1;32m    153\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data_struct\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    154\u001b[0m   }\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dict_only:\n\u001b[1;32m    156\u001b[0m   types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/utils/py_utils.py:152\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Could add support for more exotic data_struct, like OrderedDict\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    151\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 152\u001b[0m       k: \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data_struct\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    154\u001b[0m   }\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dict_only:\n\u001b[1;32m    156\u001b[0m   types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/utils/py_utils.py:167\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(mapped)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Singleton\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/download/download_manager.py:446\u001b[0m, in \u001b[0;36m_wait_on_promise\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_on_promise\u001b[39m(p):\n\u001b[0;32m--> 446\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/promise/promise.py:510\u001b[0m, in \u001b[0;36mPromise.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    508\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target()\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(timeout \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_TIMEOUT)\n\u001b[0;32m--> 510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/promise/promise.py:514\u001b[0m, in \u001b[0;36mPromise._target_settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_target_settled_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, _raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# type: (bool) -> Any\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/promise/promise.py:224\u001b[0m, in \u001b[0;36mPromise._settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _raise:\n\u001b[1;32m    223\u001b[0m     raise_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n\u001b[0;32m--> 224\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_traceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/promise/promise.py:842\u001b[0m, in \u001b[0;36m_process_future_result.<locals>.handle_future_result\u001b[0;34m(future)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_future_result\u001b[39m(future):\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;66;03m# type: (Any) -> None\u001b[39;00m\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m         resolve(\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    844\u001b[0m         tb \u001b[38;5;241m=\u001b[39m exc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/concurrent/futures/thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/usr/local/share/anaconda3/envs/ewu-dmls/lib/python3.8/site-packages/tensorflow_datasets/core/download/downloader.py:234\u001b[0m, in \u001b[0;36m_Downloader._sync_download\u001b[0;34m(self, url, destination_path)\u001b[0m\n\u001b[1;32m    232\u001b[0m   response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DownloadError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to get url \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. HTTP code: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    235\u001b[0m                         (url, response\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[1;32m    236\u001b[0m fname \u001b[38;5;241m=\u001b[39m _get_filename(response)\n\u001b[1;32m    237\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination_path, fname)\n",
      "\u001b[0;31mDownloadError\u001b[0m: Failed to get url http://data.csail.mit.edu/places/places365/train_256_places365standard.tar. HTTP code: 504."
     ]
    }
   ],
   "source": [
    "# Approximately 20 mins\n",
    "tfds.list_builders()\n",
    "data,info=tfds.load('places365_small', with_info=True)\n",
    "train_dataset=data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFfZSH-kPs9O"
   },
   "outputs": [],
   "source": [
    "# Get names of classes\n",
    "class_names=[name for name in info.features['label'].names]\n",
    "class_types=len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4-y5ij_RaVx3",
    "outputId": "336c56d5-8dcc-4564-db1c-a56d9ca1a654"
   },
   "outputs": [],
   "source": [
    "for x in train_dataset.take(5):\n",
    "  plt.imshow(x['image'])\n",
    "  plt.show()\n",
    "  print(class_names[x['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrPWusH3yRGw"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE=256\n",
    "\n",
    "@tf.function\n",
    "def preprocess(data):\n",
    "  image=data['image']\n",
    "  image=tf.cast(image,tf.float32)/127.5-1\n",
    "  image=tf.image.resize(image,(IMAGE_SIZE, IMAGE_SIZE))\n",
    "  return image,data['label']\n",
    "\n",
    "train_dataset=train_dataset.map(preprocess,num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CxyRhZaDSYk"
   },
   "outputs": [],
   "source": [
    "class ConditionBatchNormalization(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(ConditionBatchNormalization, self).__init__()\n",
    "    self.decay = 0.9\n",
    "    self.epsilon = 1e-05\n",
    "    self.test_mean=tf.Variable(initial_value=0, trainable=False, dtype=tf.float32)\n",
    "    self.test_var=tf.Variable(initial_value=1, trainable=False, dtype=tf.float32)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.num_channels=input_shape[0][-1]\n",
    "    self.beta_mapping=tf.keras.layers.Dense(self.num_channels)\n",
    "    self.gamma_mapping=tf.keras.layers.Dense(self.num_channels)\n",
    "    \n",
    "  def call(self, x, training=None):\n",
    "    #Generate beta, gamma\n",
    "    x, conditions = x\n",
    "    beta = self.beta_mapping(conditions)\n",
    "    gamma = self.gamma_mapping(conditions)\n",
    "\n",
    "    beta = tf.reshape(beta, shape=[-1, 1, 1, self.num_channels])\n",
    "    gamma = tf.reshape(gamma, shape=[-1, 1, 1, self.num_channels])\n",
    "    if training:\n",
    "        #Calculate mean and varience of X.\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2])\n",
    "        #Calculate parameters for test set \n",
    "        self.test_mean = self.test_mean * self.decay + batch_mean * (1 - self.decay)\n",
    "        self.test_var = self.test_var * self.decay + batch_var * (1 - self.decay)\n",
    "\n",
    "        return tf.nn.batch_normalization(x, batch_mean, batch_var, beta, gamma, self.epsilon)\n",
    "    else:\n",
    "        return tf.nn.batch_normalization(x, self.test_mean, self.test_var, beta, gamma, self.epsilon)\n",
    "\n",
    "class SelfAttention(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(SelfAttention, self).__init__()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.num_channels=input_shape[-1]\n",
    "    self.hw = input_shape[1]*input_shape[2]\n",
    "    self.conv_f=tf.keras.layers.Conv2D(self.num_channels // 8, 1)\n",
    "    self.conv_g=tf.keras.layers.Conv2D(self.num_channels // 8, 1)\n",
    "    self.conv_h=tf.keras.layers.Conv2D(self.num_channels//2, 1)\n",
    "    self.conv_o=tf.keras.layers.Conv2D(self.num_channels, 1)\n",
    "\n",
    "  def call(self, x):\n",
    "    bs = x.shape[0]\n",
    "    f = self.conv_f(x)  # [bs, h, w, c']\n",
    "    g = self.conv_g(x)  # [bs, h, w, c']\n",
    "    h = self.conv_h(x)  # [bs, h, w, c]\n",
    "\n",
    "    f=tf.keras.layers.Reshape([self.hw, f.shape[-1]])(f)\n",
    "    g=tf.keras.layers.Reshape([self.hw, g.shape[-1]])(g)\n",
    "    h=tf.keras.layers.Reshape([self.hw, h.shape[-1]])(h)\n",
    "    # N = h * w\n",
    "    s = tf.matmul(g, f, transpose_b=True)  # # [bs, N, N]\n",
    "    beta = tf.nn.softmax(s)  # attention map\n",
    "\n",
    "    o = tf.matmul(beta, h)  # [bs, N, C]\n",
    "    o = tf.keras.layers.Reshape([x.shape[1], x.shape[2], self.num_channels//2])(o)\n",
    "    o = self.conv_o(o)\n",
    "      # [bs, h, w, C]\n",
    "    return x + o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_9vz3IfGN7b"
   },
   "source": [
    "BIGGAN Architecture Implementations - BigGAN 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "niFGnBgGDaxv",
    "outputId": "f5be2f2a-7692-4b82-f1b4-d2b0660ae0a4"
   },
   "outputs": [],
   "source": [
    "#BigGAN 128 - G\n",
    "latent_dim = 120\n",
    "slice_latent_dim = 20\n",
    "class_dims = 128\n",
    "channels = 96\n",
    "\n",
    "def residual_block_up(image_input, concat_input, channels):  \n",
    "\n",
    "    block_a=tf.keras.layers.UpSampling2D()(image_input)\n",
    "    block_a=tf.keras.layers.Conv2D(channels,1)(block_a)\n",
    "\n",
    "    block_b=ConditionBatchNormalization()([image_input, concat_input])\n",
    "    block_b=tf.keras.layers.ReLU()(block_b)\n",
    "    block_b=tf.keras.layers.UpSampling2D()(block_b)\n",
    "    \n",
    "    block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "    block_b=ConditionBatchNormalization()([block_b, concat_input])\n",
    "    block_b=tf.keras.layers.ReLU()(block_b)\n",
    "    block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "\n",
    "    final_output=tf.keras.layers.Add()([block_a,block_b])\n",
    "    return final_output\n",
    "\n",
    "def crop_noise(noise, idx):\n",
    "    return noise[:, idx*slice_latent_dim : (idx+1)*slice_latent_dim]\n",
    "\n",
    "noise=keras.Input(shape=(latent_dim,),name='noise')\n",
    "\n",
    "input_classes=tf.keras.layers.Input(shape=(1,),name='class')\n",
    "input_classes_embedding=tf.keras.layers.Embedding(class_types,class_dims)(input_classes)\n",
    "input_classes_embedding=tf.keras.layers.Flatten()(input_classes_embedding)\n",
    "\n",
    "noise_slice=tf.keras.layers.Lambda(lambda x:crop_noise(x, idx=0))(noise)\n",
    "model=tf.keras.layers.concatenate([noise_slice,input_classes_embedding])\n",
    "model=tf.keras.layers.Dense(4* 4* 16 * channels)(model)\n",
    "model=tf.keras.layers.Reshape((4,4,16 * channels))(model)\n",
    "\n",
    "non_local_block=[False, False, False,True,False]\n",
    "channel_multipliers=[16, 8, 4, 2, 1]\n",
    "for x in range(5):\n",
    "    noise_slice=tf.keras.layers.Lambda(lambda x:crop_noise(x, idx=0))(noise)\n",
    "    concat=tf.keras.layers.concatenate([noise_slice,input_classes_embedding])\n",
    "\n",
    "    model=residual_block_up(model, concat, channels*channel_multipliers[x])\n",
    "    if non_local_block[x]:\n",
    "      model=SelfAttention()(model)\n",
    "\n",
    "model=tf.keras.layers.BatchNormalization()(model)\n",
    "model=tf.keras.layers.ReLU()(model)\n",
    "model=tf.keras.layers.Conv2D(3,3,padding='same',activation='tanh')(model)\n",
    "\n",
    "generator=tf.keras.models.Model([noise,input_classes],model)\n",
    "generator.summary()\n",
    "tf.keras.utils.plot_model(generator,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TwBhae-5GDrW",
    "outputId": "c72b83f6-ec63-4a86-d3d3-6ec6b669acad"
   },
   "outputs": [],
   "source": [
    "#BigGAN 128 - D\n",
    "def residual_block_down(input_image,channels,down=True):\n",
    "  block_a=tf.keras.layers.Conv2D(channels,1)(input_image)\n",
    "  if down:\n",
    "    block_a=tf.keras.layers.AveragePooling2D()(block_a)\n",
    "\n",
    "  block_b=tf.keras.layers.ReLU()(input_image)\n",
    "  block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "  block_b=tf.keras.layers.ReLU()(block_b)\n",
    "  block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "  if down:\n",
    "    block_b=tf.keras.layers.AveragePooling2D()(block_b)\n",
    "\n",
    "  final_output=tf.keras.layers.Add()([block_a,block_b])\n",
    "  return final_output\n",
    "\n",
    "input_image=tf.keras.layers.Input(shape=(256, 256, 3),name='image')\n",
    "\n",
    "input_classes=tf.keras.layers.Input(shape=(1,),name='class')\n",
    "input_classes_embedding=tf.keras.layers.Embedding(class_types,class_dims)(input_classes)\n",
    "input_classes_embedding=tf.keras.layers.Flatten()(input_classes_embedding)\n",
    "\n",
    "model=tf.keras.layers.Conv2D(channels,3,1,padding='same')(input_image)\n",
    "\n",
    "non_local_block=[True,False,False,False,False]\n",
    "down_list=[True,True,True,True,False]\n",
    "channel_multipliers=[2,4,8,16,16]\n",
    "for x in range(5):\n",
    "  model=residual_block_down(model,channels=channels*channel_multipliers[x],down=down_list[x])\n",
    "  if non_local_block[x]:\n",
    "    model=SelfAttention()(model)\n",
    "#Final residual block\n",
    "model=tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "\n",
    "model=tf.keras.layers.concatenate([input_classes_embedding,model])\n",
    "model=tf.keras.layers.Dense(1)(model)\n",
    "\n",
    "discriminator=tf.keras.models.Model([input_image, input_classes],model)\n",
    "discriminator.summary()\n",
    "tf.keras.utils.plot_model(discriminator,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LUDLC94GU-S"
   },
   "source": [
    "BIGGAN Architecture Implementations - BigGAN 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MCqtmEUVShlt",
    "outputId": "411ea75d-778f-4207-96e1-c6fead87c78e"
   },
   "outputs": [],
   "source": [
    "#BigGAN 256 - G\n",
    "latent_dim = 140\n",
    "slice_latent_dim=20\n",
    "class_dims = 128\n",
    "channels = 96\n",
    "\n",
    "def residual_block_up(image_input, concat_input, channels):  \n",
    "\n",
    "    block_a=tf.keras.layers.UpSampling2D()(image_input)\n",
    "    block_a=tf.keras.layers.Conv2D(channels,1)(block_a)\n",
    "\n",
    "    block_b=ConditionBatchNormalization()([image_input, concat_input])\n",
    "    block_b=tf.keras.layers.ReLU()(block_b)\n",
    "    block_b=tf.keras.layers.UpSampling2D()(block_b)\n",
    "    \n",
    "    block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "    block_b=ConditionBatchNormalization()([block_b, concat_input])\n",
    "    block_b=tf.keras.layers.ReLU()(block_b)\n",
    "    block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "\n",
    "    final_output=tf.keras.layers.Add()([block_a,block_b])\n",
    "    return final_output\n",
    "\n",
    "def crop_noise(noise, idx):\n",
    "    return noise[:, idx*slice_latent_dim : (idx+1)*slice_latent_dim]\n",
    "\n",
    "noise=keras.Input(shape=(latent_dim,),name='noise')\n",
    "\n",
    "input_classes=tf.keras.layers.Input(shape=(1,),name='class')\n",
    "input_classes_embedding=tf.keras.layers.Embedding(class_types,class_dims)(input_classes)\n",
    "input_classes_embedding=tf.keras.layers.Flatten()(input_classes_embedding)\n",
    "\n",
    "noise_slice=tf.keras.layers.Lambda(lambda x:crop_noise(x, idx=0))(noise)\n",
    "model=tf.keras.layers.concatenate([noise_slice,input_classes_embedding])\n",
    "model=tf.keras.layers.Dense(4* 4* 16 * channels)(model)\n",
    "model=tf.keras.layers.Reshape((4,4,16*channels))(model)\n",
    "\n",
    "non_local_block=[False, True, False,False,False,False,False]\n",
    "channel_multipliers=[16, 16, 8, 8, 4, 2, 1]\n",
    "for x in range(1, 7):\n",
    "    noise_slice=tf.keras.layers.Lambda(lambda x:crop_noise(x, idx=0))(noise)\n",
    "    concat=tf.keras.layers.concatenate([noise_slice,input_classes_embedding])\n",
    "\n",
    "    model=residual_block_up(model, concat, channels*channel_multipliers[x])\n",
    "    if non_local_block[x]:\n",
    "      model=SelfAttention()(model)\n",
    "\n",
    "model=tf.keras.layers.BatchNormalization()(model)\n",
    "model=tf.keras.layers.ReLU()(model)\n",
    "model=tf.keras.layers.Conv2D(3,3,padding='same',activation='tanh')(model)\n",
    "\n",
    "generator=tf.keras.models.Model([noise,input_classes],model)\n",
    "generator.summary()\n",
    "tf.keras.utils.plot_model(generator,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "j8xOajAwR4Vo",
    "outputId": "9b661671-8165-4190-a5f4-5f827064a224"
   },
   "outputs": [],
   "source": [
    "#BigGAN 256 - D\n",
    "def residual_block_down(input_image,channels,down=True):\n",
    "  block_a=tf.keras.layers.Conv2D(channels,1)(input_image)\n",
    "  if down:\n",
    "    block_a=tf.keras.layers.AveragePooling2D()(block_a)\n",
    "\n",
    "  block_b=tf.keras.layers.ReLU()(input_image)\n",
    "  block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "  block_b=tf.keras.layers.ReLU()(block_b)\n",
    "  block_b=tf.keras.layers.Conv2D(channels,3,padding='same')(block_b)\n",
    "  if down:\n",
    "    block_b=tf.keras.layers.AveragePooling2D()(block_b)\n",
    "\n",
    "  final_output=tf.keras.layers.Add()([block_a,block_b])\n",
    "  return final_output\n",
    "\n",
    "input_image=tf.keras.layers.Input(shape=(256, 256, 3),name='image')\n",
    "\n",
    "input_classes=tf.keras.layers.Input(shape=(1,),name='class')\n",
    "input_classes_embedding=tf.keras.layers.Embedding(class_types,class_dims)(input_classes)\n",
    "input_classes_embedding=tf.keras.layers.Flatten()(input_classes_embedding)\n",
    "\n",
    "model=tf.keras.layers.Conv2D(channels,3,1,padding='same')(input_image)\n",
    "\n",
    "non_local_block=[False,False,False,True,False,False,False]\n",
    "down_list=[True,True,True,True,True,True,False]\n",
    "channel_multipliers=[2,4,8,8,16,16,16]\n",
    "for x in range(7):\n",
    "  model=residual_block_down(model,channels=channels*channel_multipliers[x],down=down_list[x])\n",
    "  if non_local_block[x]:\n",
    "    model=SelfAttention()(model)\n",
    "#Final residual block\n",
    "model=tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "\n",
    "model=tf.keras.layers.concatenate([input_classes_embedding,model])\n",
    "model=tf.keras.layers.Dense(1)(model)\n",
    "\n",
    "discriminator=tf.keras.models.Model([input_image, input_classes],model)\n",
    "discriminator.summary()\n",
    "tf.keras.utils.plot_model(discriminator,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFVDyhDai4E2"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, g_loss_fn, d_loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, data_batch):\n",
    "        real_images,anno=data_batch\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        fake_anno=tf.cast(tf.random.uniform(shape=[batch_size,1]) * class_types, tf.int32)\n",
    "\n",
    "        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "            generated_images = self.generator({'noise':random_latent_vectors, 'class':fake_anno})\n",
    "            gen_predictions = self.discriminator({'image':generated_images,'class':fake_anno})\n",
    "            real_predictions = self.discriminator({'image':real_images,'class':anno})\n",
    "            d_loss = self.d_loss_fn(real_predictions, gen_predictions)\n",
    "            g_loss = self.g_loss_fn(gen_predictions)\n",
    "\n",
    "        d_grads = d_tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(d_grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        g_grads = g_tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_weights))\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYamIj1RSzWj"
   },
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=100, noise=None, anno=None):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        if noise==None:\n",
    "          self.random_latent_vectors = random_latent_vectors = tf.random.normal(shape=(num_img, latent_dim))\n",
    "        else:\n",
    "          self.random_latent_vectors=noise\n",
    "        \n",
    "        if anno==None:\n",
    "          self.fake_anno=fake_anno=tf.cast(np.tile(np.arange(10),10),tf.int32)\n",
    "        else:\n",
    "          self.fake_anno=anno\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.model.generator({'noise':self.random_latent_vectors,'class':self.fake_anno})\n",
    "        generated_images = generated_images*127.5+127.5\n",
    "        generated_images.numpy()\n",
    "\n",
    "        fig=plt.figure(figsize=(20,20))\n",
    "        for i in range(self.num_img):\n",
    "            plt.subplot(10,10,i + 1)\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "        plt.savefig(f'generated_image_EPOCH_{epoch}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzsItXtwS1vN"
   },
   "outputs": [],
   "source": [
    "num_img=100\n",
    "random_latent_vectors = tf.random.normal(shape=(num_img, latent_dim))\n",
    "fake_anno=tf.cast(np.tile(np.arange(10),10),tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxFhynvXKwVs"
   },
   "outputs": [],
   "source": [
    "def hinge_loss_d(true_pred, fake_pred):\n",
    "  real_loss=tf.math.minimum(tf.zeros_like(true_pred), -1 + true_pred)\n",
    "  fake_loss=tf.math.minimum(tf.zeros_like(fake_pred), -1 - fake_pred)\n",
    "  return real_loss + fake_loss\n",
    "def hinge_loss_g(fake_pred):\n",
    "  return fake_pred\n",
    "\n",
    "bce=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def generator_ce(fake_output):\n",
    "  return bce(tf.zeros_like(fake_output),fake_output)\n",
    "def discriminator_ce(real_output, fake_output):\n",
    "  real_loss = bce(tf.zeros_like(real_output), real_output)\n",
    "  fake_loss = bce(tf.ones_like(fake_output), fake_output)\n",
    "  total_loss = real_loss + fake_loss\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f5nPp3fYqO2Z",
    "outputId": "28b02f68-df61-452c-c508-fd944f6370ad"
   },
   "outputs": [],
   "source": [
    "gen_images=generator({'noise':random_latent_vectors,'class':fake_anno})\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i + 1)\n",
    "    img = keras.preprocessing.image.array_to_img(gen_images[i])\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print(discriminator({'image':gen_images,'class':fake_anno}).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PCcxjX3PTPio",
    "outputId": "66de0a79-9178-426f-f9f2-bc837b0e280e"
   },
   "outputs": [],
   "source": [
    "epochs = 100  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    d_loss_fn=hinge_loss_d,\n",
    "    g_loss_fn=hinge_loss_g,\n",
    ")\n",
    "\n",
    "gan.fit(train_dataset.batch(128), epochs=epochs, callbacks=[GANMonitor(num_img=num_img, latent_dim=latent_dim, noise=random_latent_vectors, anno=fake_anno)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-6xyKmqVuB4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BIGGAN-256-Places365.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
